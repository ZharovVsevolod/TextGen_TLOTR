{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ранагон\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.poetry import *\n",
    "from utils.base import *\n",
    "from utils.transformer_tools import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import youtokentome as yttm\n",
    "import mauve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "horus = load_chunks(\"./datasets/TLotR_red.txt\", chunk_size=300)\n",
    "horus = horus[12000:13000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPE_MODEL_FILENAME = './models/tokens/lord_bpe_1000_new.yttm'\n",
    "tokenizer = yttm.BPE(BPE_MODEL_FILENAME)\n",
    "\n",
    "G_model = Language_Model(\n",
    "    vocab_size = tokenizer.vocab_size(),\n",
    "    embedding_size = 256,\n",
    "    backbone = Transformer_Encoder(\n",
    "        nn.TransformerEncoderLayer(\n",
    "            d_model = 256,\n",
    "            nhead = 16,\n",
    "            dim_feedforward = 512,\n",
    "            dropout = 0.1\n",
    "        ),\n",
    "        num_layers=5\n",
    "    ),\n",
    "    emb_dropout = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model.load_state_dict(torch.load('./models/GAN/4/model_G.pth'))\n",
    "G_model.eval()\n",
    "G_model.cuda()\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]d:\\Programs\\TextGen\\utils\\poetry.py:205: RuntimeWarning: invalid value encountered in log\n",
      "  distribution = np.log(original) / temperature\n",
      "d:\\Programs\\TextGen\\utils\\poetry.py:267: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  next_tokens_logproba = F.log_softmax(next_tokens_logits)\n",
      "100%|██████████| 1000/1000 [15:38<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "loop_generator = Gen_method(G_model, tokenizer)\n",
    "fake_horus = []\n",
    "for i in tqdm(range(len(horus))):\n",
    "    try:\n",
    "        fake_horus.append(loop_generator(horus[i], N_cut=15, need_reweight=True, temper=0.3, alpha=0.15))\n",
    "    except KeyboardInterrupt:\n",
    "        print('Досрочно остановлено пользователем')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nazgul down below them to the bank, and then began to run swiftly down, until they came to a wide open window. The hobbits saw that they had come to a wide shallow b\n"
     ]
    }
   ],
   "source": [
    "fake_horus_gan = []\n",
    "\n",
    "for i in fake_horus:\n",
    "    fake_horus_gan.append(i[0])\n",
    "\n",
    "print(fake_horus_gan[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_texts_to_file(fake_horus_gan, \"./datasets/TLOTR_fake_rankgen.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model.load_state_dict(torch.load('./models/Lord/4/Lord.pth'))\n",
    "G_model.eval()\n",
    "G_model.cuda()\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [15:36<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "loop_generator = Gen_method(G_model, tokenizer)\n",
    "fake_horus = []\n",
    "for i in tqdm(range(len(horus))):\n",
    "    try:\n",
    "        fake_horus.append(loop_generator(horus[i], N_cut=15, need_reweight=True, temper=0.3, alpha=0.15))\n",
    "    except KeyboardInterrupt:\n",
    "        print('Досрочно остановлено пользователем')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nazgul down below them to the bank, and then began to run swiftly down, until they came to a wide open window. The hobbits saw that they had come to a wide shallow b\n"
     ]
    }
   ],
   "source": [
    "fake_horus_old = []\n",
    "\n",
    "for i in fake_horus:\n",
    "    fake_horus_old.append(i[0])\n",
    "\n",
    "print(fake_horus_old[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_texts_to_file(fake_horus_old, \"./datasets/TLOTR_fake_rankgen_old.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "again. He stooped and looked at him with wonder. 'Good!' he said. 'Did you hear me?' he asked. 'Yes, I am afraid. I am afraid.\n",
      "again. He stooped and looked at him with wonder. 'Good!' he said. 'Did you hear me?' he asked. 'Yes, I am afraid. I am afraid.\n"
     ]
    }
   ],
   "source": [
    "print(fake_horus_gan[10])\n",
    "print(fake_horus_old[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing p: 100%|██████████| 100/100 [01:55<00:00,  1.15s/it]\n",
      "Featurizing q: 100%|██████████| 100/100 [00:58<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33214193752176907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing p: 100%|██████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "Featurizing q: 100%|██████████| 100/100 [00:58<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33214193752176907\n"
     ]
    }
   ],
   "source": [
    "out_old = mauve.compute_mauve(p_text=horus[:100], q_text=fake_horus_old[:100])\n",
    "print(out_old.mauve)\n",
    "\n",
    "out_gan = mauve.compute_mauve(p_text=horus[:100], q_text=fake_horus_gan[:100])\n",
    "print(out_gan.mauve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
